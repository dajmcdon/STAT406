{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT406 - Lecture 2 notes\n",
    "================\n",
    "Matias Salibian-Barrera\n",
    "2019-09-10\n",
    "\n",
    "#### LICENSE\n",
    "\n",
    "These notes are released under the “Creative Commons\n",
    "Attribution-ShareAlike 4.0 International” license. See the\n",
    "**human-readable version**\n",
    "[here](https://creativecommons.org/licenses/by-sa/4.0/) and the **real\n",
    "thing**\n",
    "[here](https://creativecommons.org/licenses/by-sa/4.0/legalcode).\n",
    "\n",
    "## Lecture slides\n",
    "\n",
    "The lecture slides are [here](STAT406-19-lecture-2.pdf).\n",
    "\n",
    "## Predictions using a linear model\n",
    "\n",
    "In these notes we continue looking at the problem of comparing different\n",
    "models based on their prediction properties. As in the previous lecture,\n",
    "we consider a **full** and a **reduced** model, and in all that follows\n",
    "we assume that the variables included in the **reduced** model were not\n",
    "selected using the training data. **This seemingly innocent assumption\n",
    "is in fact critical, and we will later come back to it.**\n",
    "\n",
    "### Estimating the MSPE with a test set\n",
    "\n",
    "One way to estimate the mean squared prediction error of a model or\n",
    "predictor is to use it on a test set (where the responses are known, but\n",
    "that was not used when training the predcitor or estimating the model),\n",
    "and the comparing the predictions with the actual responses.\n",
    "\n",
    "First, we load the training set and fit both\n",
    "models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.tr <- read.table('../Lecture1/pollution-train.dat', header=TRUE, sep=',')\n",
    "full <- lm(MORT ~ . , data=x.tr)\n",
    "reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x.tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the **full** model fits the data better than the reduced one\n",
    "(see Lecture 1), its predictions on the test set are better. First,\n",
    "compute the two vectors of test set\n",
    "predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.te <- read.table('../Lecture1/pollution-test.dat', header=TRUE, sep=',')\n",
    "pr.full <- predict(full, newdata=x.te)\n",
    "pr.reduced <- predict(reduced, newdata=x.te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, use them to estimate the mean squared prediction error of each\n",
    "model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(x.te, mean( (MORT - pr.full)^2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(x.te, mean( (MORT - pr.reduced)^2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lecture 1 we also saw that this is not just an artifact of the\n",
    "specific training / test split of the data. The **reduced** model\n",
    "generally produces better predictions, regardless of the specific\n",
    "training / test split we use. We can verify this repeating the procedure\n",
    "many times (100, say) and looking at the estimated mean squared\n",
    "prediction errors obtained each time for each model.\n",
    "\n",
    "\n",
    "### Leave-one-out cross-validation\n",
    "\n",
    "A different procedure to estimate the prediction power of a model or\n",
    "method is called **leave-one-out CV**. One advantage of using this\n",
    "method is that the model we fit can use a larger training set. We\n",
    "discussed the procedure in class. Here we apply it to estimate the mean\n",
    "squared prediction error of the **full** and **reduced** models. Again,\n",
    "we assume that the reduced model was chosen independently from the\n",
    "training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- read.csv('../Lecture1/rutgers-lib-30861_CSV-1.csv')\n",
    "n <- nrow(x)\n",
    "pr.full <- pr.reduced <- rep(0, n)\n",
    "for(i in 1:n) {\n",
    "  full <- lm(MORT ~ . , data=x[-i, ])\n",
    "  reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x[-i, ])\n",
    "  pr.full[i] <- predict(full, newdata = x[i, ])\n",
    "  pr.reduced[i] <- predict(reduced, newdata = x[i, ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the leave-one-out predictions for each model and can compute\n",
    "the corresponding estimated mean squared prediction errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean( (x$MORT - pr.full)^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean( (x$MORT - pr.reduced)^2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here again the reduced model seems to yield better prediction\n",
    "errors.\n",
    "\n",
    "### K-fold cross-validation\n",
    "\n",
    "Leave-one-out cross-validation can be computationally very demanding (or\n",
    "even unfeasible) when the sample size is large and training the\n",
    "predictor is relatively costly. One solution is called **K-fold CV**. We\n",
    "split the data into **K** folds, train the predictor on the data without\n",
    "a fold, and use it to predict the responses in the removed fold. We\n",
    "cycle through the folds, and use the average of the squared prediction\n",
    "errors as an estimate of the mean squared prediction error. The\n",
    "following script does **5-fold CV** for the `full` and `reduced` linear\n",
    "models on the pollution dataset, once again assuming that the reduced\n",
    "model was originally chosen without using the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(x)\n",
    "k <- 5\n",
    "pr.full <- pr.reduced <- rep(0, n)\n",
    "# Create labels for the \"folds\"\n",
    "inds <- (1:n) %% k + 1 \n",
    "# shuffle the rows of x, this is bad coding!\n",
    "set.seed(123)\n",
    "xs <- x[ sample(n, repl=FALSE), ]\n",
    "# loop through the folds\n",
    "for(j in 1:k) {\n",
    "  x.tr <- xs[inds != j, ]\n",
    "  x.te <- xs[inds == j, ]\n",
    "  full <- lm(MORT ~ . , data=x.tr)\n",
    "  reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x.tr)\n",
    "  pr.full[ inds== j] <- predict(full, newdata=x.te)\n",
    "  pr.reduced[ inds==j ] <- predict(reduced, newdata=x.te)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the estimated mean squared prediction error of each\n",
    "model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean( (xs$MORT - pr.full)^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean( (xs$MORT - pr.reduced)^2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is clearly faster than leave-one-out CV, but the results may\n",
    "depend on the specific fold partition, and on the number **K** of folds\n",
    "used.\n",
    "\n",
    "  - One way to obtain more stable mean squared prediction errors using\n",
    "    K-fold CV is to repeat the above procedure many times, and compare\n",
    "    the distribution of the mean squared prediction errors for each\n",
    "    estimator. First, fit the **full** and **reduced** models using the\n",
    "    whole data set as training:\n",
    "\n",
    "<!-- end list -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.f <- lm(MORT ~ . , data=x)\n",
    "m.r <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 50 runs of 5-fold CV comparing the **full** and **reduced**\n",
    "models. Again, here we assume that the reduced model was not obtained\n",
    "using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N <- 50\n",
    "mspe1 <- mspe2 <- vector('double', N)\n",
    "ii <- (1:(n <- nrow(x))) %% 5 + 1\n",
    "set.seed(327)\n",
    "for(i in 1:N) {\n",
    "  ii <- sample(ii)\n",
    "  pr.f <- pr.r <- vector('double', n)\n",
    "  for(j in 1:5) {\n",
    "    pr.f[ ii == j ] <- predict(update(m.f, data=x[ii != j, ]), newdata=x[ii==j,])\n",
    "    pr.r[ ii == j ] <- predict(update(m.r, data=x[ii != j, ]), newdata=x[ii==j,])\n",
    "  }\n",
    "  mspe1[i] <- with(x, mean( (MORT - pr.f)^2 ))\n",
    "  mspe2[i] <- with(x, mean( (MORT - pr.r)^2 ))\n",
    "}  \n",
    "boxplot(mspe1, mspe2, names=c('Full', 'Reduced'), \n",
    "        col=c('gray80', 'tomato3'), \n",
    "        main='Air Pollution - 50 runs 5-fold CV', ylim=c(0, 5000))\n",
    "mtext(expression(hat(MSPE)), side=2, line=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the estimated mean squared prediction error of the **reduced**\n",
    "model has a smaller mean / median than that of the **full** one. This\n",
    "tells us that the conclusion we reached favouring the reduced model (in\n",
    "terms of its prediction mean squared error) does not depend on a\n",
    "particular choice of folds. In other words, this provides more evidence\n",
    "to conclude that the reduced model will produce better predictions than\n",
    "the full one.\n",
    "\n",
    "  - A computationally simpler (albeit possibly less precise) way to\n",
    "    account for the K-fold variability is to run K-fold CV once and use\n",
    "    the sample standard error of the **K** *smaller* mean squared\n",
    "    prediction errors to construct a rough *confidence interval* around\n",
    "    the overall mean squared prediction error estimate (that is the\n",
    "    average of the mean squared prediction errors over the K folds).\n",
    "\n",
    "  - The dependency of this MSPE on **K** is more involved. We will\n",
    "    discuss it later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
